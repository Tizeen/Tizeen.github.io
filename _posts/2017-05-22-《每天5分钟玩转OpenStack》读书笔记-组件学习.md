---
layout: post
title: 每天5分钟玩转OpenStack - 组件学习
date: 2017-05-22 23:00:53 +0800
categories: 读书笔记
---

OpenStack作为云操作系统，由很多组件构成，这里记录对各个组件的简单学习。




## Glance架构

![](http://ww1.sinaimg.cn/large/9bbe7ebdgy1fftbonllf4j20fp0dx74p.jpg)

- glance-api: 对外提供接口，根据请求类型将请求转发给glance-registry或者store backend处理
- glance-registry: 系统后台运行的服务进程，处理和存取image的metadata
- Database(MySQL): 存储image的metadata信息
- Store backend: image的真正存储位置，支持多种类型的backend（普通文件系统、Swift、Amazon S3、Ceph...）

## Image类型

- Raw
- vhd: VMWare
- vmdk
- VDI: VirtualBox
- ISO: CDROM
- QCOW2: Qemu emulator(support copy on write)
- aki: Amazon kernel image
- ari: Amazon ramdisk image
- ami: Amazon machine image

## Cinder架构

- cinder-api: 接收API请求
- cinder-volume: 管理volume服务，与volume provider协调工作，管理volume生命周期。运行cinder-vulume服务的节点就是存储节点
- cinder-scheduler: 调度选择合适的存储节点创建volume
- Message Queue(Rabbit MQ): 消息服务
- Database(MySQL): 存放Cinder数据

Cinder子服务工作流与Nova差不多

注意点：

1. cinder-volume自身不管理真正的存储设备，存储设备是由`volume provider`来管理。cinder-volume和volume provider共同实现volume的生命周期管理； 
2. OpenStack通过`iSCSI`将Cinder创建的虚拟硬盘挂载到实例中使用(Attach volume)；

iSCSI:

- Target: 服务端，提供iSCSI存储资源的设备
- Initiator: 客户端， cinder-volume使用tgt软件来管理和监控iSCSI Target

## Nova架构

- nova-api: 接收响应客户端API调用
- nova-scheduler: 调度服务，决定虚拟机在哪个节点上运行
- nova-compute: 调用Hypervisor API实现虚拟机的生命周期
- Hypervisor: 虚拟化管理程序
- nova-coductor: 访问数据库
- nova-console: 访问虚拟机控制台
- nova-consoleauth: 访问虚拟机控制台请求token认证
- nova-cert: 证书支持
- Database: 存放数据(MySQL)

## 从创建虚拟机看nova-*子服务如何协同工作

![](http://ww1.sinaimg.cn/large/9bbe7ebdgy1femlzn3d4aj20cw0cwaa7.jpg)

解释：

1. 客户向nova-api发送一个“创建虚拟机”的 请求；
2. API做一些必要处理之后，向消息服务RabbitMQ发送一条创建虚拟机的消息；
3. Scheduler调度器从Messaging中获取API发送的消息，执行调度算法，从若干计算节点中计算出节点A；
4. Scheduler想Messaging中发送一个“在节点A创建虚拟机”的消息；
5. 节点A获取到Messaging中Scheduler发送给他的消息，发现是创建一个新的虚拟机，然后再Hypervisor上启动虚拟机；
6. 创建虚拟机过程中，需要查询数据库或更新数据库信息，通过Messaging想Conductor发送消息，Coductor负责数据库访问；

程序调用方式：

- 同步调用：执行调用之后，等待返回之后才会执行其他操作
- 异步调用：执行调用之后，无需等待结果返回，直接继续后面的工作

OpenStack中通常采用**异步调用**的方式。

## Neutron架构
- Neutron Server: 对外提供API，接收请求，调用Plugin处理请求
- Plugin: 处理Server发来的请求，维护OpenStack的网络状态，调用Agent处理请求
- Agent: 处理Plugin请求，负责在Network provider上实现各种网络功能
- Network provider: 提供网络服务的虚拟或物理网络设备，例如：Linux Bridge、Open vSwitch
- Queue: 队列（异步调用）
- Database: 存放OpenStack的网络信息

Plugin、Agent、Network provider配套使用。

Plugin分类：
- core plugin: 维护network、subnet和port相关资源信息，对应agent有Linux Bridge、OVS等
- service plugin: 提供routing、firewall、load balance等服务

## 网络类型

- local: 隔绝的局域网，位于相同local网络内的instance可以互相连通，不同local网络的instance不能通信
- flat: 无vlan tagging的网络，要求宿主机的物理网卡直接与Linux Bridge相连，每个flat network都会独占一个物理网卡
- vlan: 虚拟局域网，不同vlan之间通过route通信
- vxlan: overlay网络，虚拟扩展局域网
- gre: overlay网络
